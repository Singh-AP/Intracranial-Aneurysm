{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densepoint.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXdYwoonaLaBFYMk5Mcknu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Singh-AP/Intracranial-Aneurysm/blob/main/Densepoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEATp_XcMLUK",
        "outputId": "0d39e056-b362-4637-ee66-8e6e40074632"
      },
      "source": [
        "!git clone https://github.com/Yochengliu/DensePoint.git\n",
        "!cp -R DensePoint/* .\n",
        "!mkdir build && cd build\n",
        "!cmake . && make \n",
        "# !pip install torch==1.7.\n",
        "# !pip install --upgrade torchvision\n",
        "# !pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DensePoint' already exists and is not an empty directory.\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content\n",
            "[ 20%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/cuda_compile_1.dir/utils/csrc/cuda_compile_1_generated_ball_query_gpu.cu.o\u001b[0m\n",
            "[ 40%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/cuda_compile_1.dir/utils/csrc/cuda_compile_1_generated_group_points_gpu.cu.o\u001b[0m\n",
            "[ 60%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/cuda_compile_1.dir/utils/csrc/cuda_compile_1_generated_interpolate_gpu.cu.o\u001b[0m\n",
            "[ 80%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/cuda_compile_1.dir/utils/csrc/cuda_compile_1_generated_sampling_gpu.cu.o\u001b[0m\n",
            "[100%] \u001b[34m\u001b[1mGenerating utils/_ext/pointnet2/_pointnet2.so\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/utils/build_ffi.py\", line 4, in <module>\n",
            "    from torch.utils.ffi import create_extension\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/ffi/__init__.py\", line 1, in <module>\n",
            "    raise ImportError(\"torch.utils.ffi is deprecated. Please use cpp extensions instead.\")\n",
            "ImportError: torch.utils.ffi is deprecated. Please use cpp extensions instead.\n",
            "CMakeFiles/pointnet2_ext.dir/build.make:67: recipe for target 'utils/_ext/pointnet2/_pointnet2.so' failed\n",
            "make[2]: *** [utils/_ext/pointnet2/_pointnet2.so] Error 1\n",
            "CMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/pointnet2_ext.dir/all' failed\n",
            "make[1]: *** [CMakeFiles/pointnet2_ext.dir/all] Error 2\n",
            "Makefile:83: recipe for target 'all' failed\n",
            "make: *** [all] Error 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFhfjeMUkkEa",
        "outputId": "a0b87055-9453-4f41-e990-b54f3a329669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !pip install torch-encoding==0.3.1\n",
        "# !nvidia-smi\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec  3 13:31:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    33W / 250W |      1MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdECVF3Oi2bc"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import tempfile\n",
        "import shutil\n",
        "from functools import wraps, reduce\n",
        "from string import Template\n",
        "import torch\n",
        "import torch.cuda\n",
        "from torch._utils import _accumulate\n",
        "\n",
        "try:\n",
        "\timport cffi\n",
        "except ImportError:\n",
        "\traise ImportError(\"torch.utils.ffi requires the cffi package\")\n",
        "\n",
        "\n",
        "if cffi.__version_info__ < (1, 4, 0):\n",
        "\traise ImportError(\"torch.utils.ffi requires cffi version >= 1.4, but \"\n",
        "\t\t\t\t\t  \"got \" + '.'.join(map(str, cffi.__version_info__)))\n",
        "\n",
        "\n",
        "def _generate_typedefs():\n",
        "\ttypedefs = []\n",
        "\tfor t in ['Double', 'Float', 'Long', 'Int', 'Short', 'Char', 'Byte']:\n",
        "\t\tfor lib in ['TH', 'THCuda']:\n",
        "\t\t\tfor kind in ['Tensor', 'Storage']:\n",
        "\t\t\t\tpython_name = t + kind\n",
        "\t\t\t\tif t == 'Float' and lib == 'THCuda':\n",
        "\t\t\t\t\tth_name = 'THCuda' + kind\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tth_name = lib + t + kind\n",
        "\t\t\t\tth_struct = 'struct ' + th_name\n",
        "\n",
        "\t\t\t\ttypedefs += ['typedef {} {};'.format(th_struct, th_name)]\n",
        "\t\t\t\t# We have to assemble a string here, because we're going to\n",
        "\t\t\t\t# do this lookup based on tensor.type(), which returns a\n",
        "\t\t\t\t# string (not a type object, as this code was before)\n",
        "\t\t\t\tpython_module = 'torch.cuda' if lib == 'THCuda' else 'torch'\n",
        "\t\t\t\tpython_class = python_module + '.' + python_name\n",
        "\t\t\t\t_cffi_to_torch[th_struct] = python_class\n",
        "\t\t\t\t_torch_to_cffi[python_class] = th_struct\n",
        "\treturn '\\n'.join(typedefs) + '\\n'\n",
        "_cffi_to_torch = {}\n",
        "_torch_to_cffi = {}\n",
        "_typedefs = _generate_typedefs()\n",
        "\n",
        "\n",
        "PY_MODULE_TEMPLATE = Template(\"\"\"\n",
        "from torch.utils.ffi import _wrap_function\n",
        "from .$cffi_wrapper_name import lib as _lib, ffi as _ffi\n",
        "\n",
        "__all__ = []\n",
        "def _import_symbols(locals):\n",
        "\tfor symbol in dir(_lib):\n",
        "\t\tfn = getattr(_lib, symbol)\n",
        "\t\tif callable(fn):\n",
        "\t\t\tlocals[symbol] = _wrap_function(fn, _ffi)\n",
        "\t\telse:\n",
        "\t\t\tlocals[symbol] = fn\n",
        "\t\t__all__.append(symbol)\n",
        "\n",
        "_import_symbols(locals())\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "def _setup_wrapper(with_cuda):\n",
        "\there = os.path.abspath(os.path.dirname(__file__))\n",
        "\tlib_dir = os.path.join(here, '..', '..', 'lib')\n",
        "\tinclude_dirs = [\n",
        "\t\tos.path.join(lib_dir, 'include'),\n",
        "\t\tos.path.join(lib_dir, 'include', 'TH'),\n",
        "\t]\n",
        "\n",
        "\twrapper_source = '#include <TH/TH.h>\\n'\n",
        "\tif with_cuda:\n",
        "\t\timport torch.cuda\n",
        "\t\twrapper_source += '#include <THC/THC.h>\\n'\n",
        "\t\tif os.sys.platform == 'win32':\n",
        "\t\t\tcuda_include_dirs = glob.glob(os.getenv('CUDA_PATH', '') + '/include')\n",
        "\t\t\tcuda_include_dirs += glob.glob(os.getenv('NVTOOLSEXT_PATH', '') + '/include')\n",
        "\t\telse:\n",
        "\t\t\tcuda_include_dirs = glob.glob('/usr/local/cuda/include')\n",
        "\t\t\tcuda_include_dirs += glob.glob('/Developer/NVIDIA/CUDA-*/include')\n",
        "\t\tinclude_dirs.append(os.path.join(lib_dir, 'include', 'THC'))\n",
        "\t\tinclude_dirs.extend(cuda_include_dirs)\n",
        "\treturn wrapper_source, include_dirs\n",
        "\n",
        "\n",
        "def _create_module_dir(base_path, fullname):\n",
        "\tmodule, _, name = fullname.rpartition('.')\n",
        "\tif not module:\n",
        "\t\ttarget_dir = name\n",
        "\telse:\n",
        "\t\ttarget_dir = reduce(os.path.join, fullname.split('.'))\n",
        "\ttarget_dir = os.path.join(base_path, target_dir)\n",
        "\ttry:\n",
        "\t\tos.makedirs(target_dir)\n",
        "\texcept os.error:\n",
        "\t\tpass\n",
        "\tfor dirname in _accumulate(fullname.split('.'), os.path.join):\n",
        "\t\tinit_file = os.path.join(base_path, dirname, '__init__.py')\n",
        "\t\topen(init_file, 'a').close()  # Create file if it doesn't exist yet\n",
        "\treturn name, target_dir\n",
        "\n",
        "\n",
        "def _build_extension(ffi, cffi_wrapper_name, target_dir, verbose):\n",
        "\ttry:\n",
        "\t\ttmpdir = tempfile.mkdtemp()\n",
        "\t\text_suf = '.pyd' if os.sys.platform == 'win32' else '.so'\n",
        "\t\tlibname = cffi_wrapper_name + ext_suf\n",
        "\t\toutfile = ffi.compile(tmpdir=tmpdir, verbose=verbose, target=libname)\n",
        "\t\tshutil.copy(outfile, os.path.join(target_dir, libname))\n",
        "\tfinally:\n",
        "\t\tshutil.rmtree(tmpdir)\n",
        "\n",
        "\n",
        "def _make_python_wrapper(name, cffi_wrapper_name, target_dir):\n",
        "\tpy_source = PY_MODULE_TEMPLATE.substitute(name=name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t  cffi_wrapper_name=cffi_wrapper_name)\n",
        "\twith open(os.path.join(target_dir, '__init__.py'), 'w') as f:\n",
        "\t\tf.write(py_source)\n",
        "\n",
        "\n",
        "def create_extension(name, headers, sources, verbose=True, with_cuda=False,\n",
        "\t\t\t\t\t package=False, relative_to='.', **kwargs):\n",
        "\tbase_path = os.path.abspath(os.path.dirname(relative_to))\n",
        "\tname_suffix, target_dir = _create_module_dir(base_path, name)\n",
        "\tif not package:\n",
        "\t\tcffi_wrapper_name = '_' + name_suffix\n",
        "\telse:\n",
        "\t\tcffi_wrapper_name = (name.rpartition('.')[0] +\n",
        "\t\t\t\t\t\t\t '.{0}._{0}'.format(name_suffix))\n",
        "\n",
        "\twrapper_source, include_dirs = _setup_wrapper(with_cuda)\n",
        "\tinclude_dirs.extend(kwargs.pop('include_dirs', []))\n",
        "\n",
        "\tif os.sys.platform == 'win32':\n",
        "\t\tlibrary_dirs = glob.glob(os.getenv('CUDA_PATH', '') + '/lib/x64')\n",
        "\t\tlibrary_dirs += glob.glob(os.getenv('NVTOOLSEXT_PATH', '') + '/lib/x64')\n",
        "\n",
        "\t\there = os.path.abspath(os.path.dirname(__file__))\n",
        "\t\tlib_dir = os.path.join(here, '..', '..', 'lib')\n",
        "\n",
        "\t\tlibrary_dirs.append(os.path.join(lib_dir))\n",
        "\telse:\n",
        "\t\tlibrary_dirs = []\n",
        "\tlibrary_dirs.extend(kwargs.pop('library_dirs', []))\n",
        "\n",
        "\tif isinstance(headers, str):\n",
        "\t\theaders = [headers]\n",
        "\tall_headers_source = ''\n",
        "\tfor header in headers:\n",
        "\t\twith open(os.path.join(base_path, header), 'r') as f:\n",
        "\t\t\tall_headers_source += f.read() + '\\n\\n'\n",
        "\n",
        "\tffi = cffi.FFI()\n",
        "\tsources = [os.path.join(base_path, src) for src in sources]\n",
        "\t# NB: TH headers are C99 now\n",
        "\tkwargs['extra_compile_args'] = ['-std=c99'] + kwargs.get('extra_compile_args', [])\n",
        "\tffi.set_source(cffi_wrapper_name, wrapper_source + all_headers_source,\n",
        "\t\t\t\t   sources=sources,\n",
        "\t\t\t\t   include_dirs=include_dirs,\n",
        "\t\t\t\t   library_dirs=library_dirs, **kwargs)\n",
        "\tffi.cdef(_typedefs + all_headers_source)\n",
        "\n",
        "\t_make_python_wrapper(name_suffix, '_' + name_suffix, target_dir)\n",
        "\n",
        "\tdef build():\n",
        "\t\t_build_extension(ffi, cffi_wrapper_name, target_dir, verbose)\n",
        "\tffi.build = build\n",
        "\treturn ffi\n",
        "\n",
        "def _wrap_function(function, ffi):\n",
        "\t@wraps(function)\n",
        "\tdef safe_call(*args, **kwargs):\n",
        "\t\targs = tuple(ffi.cast(_torch_to_cffi.get(arg.type(), 'void') + '*', arg._cdata)\n",
        "\t\t\t\t\t if isinstance(arg, torch.Tensor) or torch.is_storage(arg)\n",
        "\t\t\t\t\t else arg\n",
        "\t\t\t\t\t for arg in args)\n",
        "\t\targs = (function,) + args\n",
        "\t\tresult = torch._C._safe_call(*args, **kwargs)\n",
        "\t\tif isinstance(result, ffi.CData):\n",
        "\t\t\ttypeof = ffi.typeof(result)\n",
        "\t\t\tif typeof.kind == 'pointer':\n",
        "\t\t\t\tcdata = int(ffi.cast('uintptr_t', result))\n",
        "\t\t\t\tcname = typeof.item.cname\n",
        "\t\t\t\tif cname in _cffi_to_torch:\n",
        "\t\t\t\t\t# TODO: Maybe there is a less janky way to eval\n",
        "\t\t\t\t\t# off of this\n",
        "\t\t\t\t\treturn eval(_cffi_to_torch[cname])(cdata=cdata)\n",
        "\t\treturn result\n",
        "\treturn safe_call"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "EqkXkmdKMWai",
        "outputId": "bd96f0aa-ea25-492b-ae53-48bde57dbdb6"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_sched\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from models import DensePointCls_L6 as DensePoint\n",
        "from data import ModelNet40Cls\n",
        "import utils.pytorch_utils as pt_utils\n",
        "import utils.pointnet2_utils as pointnet2_utils\n",
        "import data.data_utils as d_utils\n",
        "import argparse\n",
        "import random\n",
        "import yaml\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)            \n",
        "torch.cuda.manual_seed(seed)       \n",
        "torch.cuda.manual_seed_all(seed)   \n",
        "\n",
        "parser = argparse.ArgumentParser(description='DensePoint Shape Classification Training')\n",
        "parser.add_argument('--config', default='cfgs/config_cls.yaml', type=str)\n",
        "\n",
        "def main():\n",
        "    args = parser.parse_args()\n",
        "    with open(args.config) as f:\n",
        "        config = yaml.load(f)\n",
        "    print(\"\\n**************************\")\n",
        "    for k, v in config['common'].items():\n",
        "        setattr(args, k, v)\n",
        "        print('\\n[%s]:'%(k), v)\n",
        "    print(\"\\n**************************\\n\")\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(args.save_path)\n",
        "    except OSError:\n",
        "        pass\n",
        "    \n",
        "    train_transforms = transforms.Compose([\n",
        "        d_utils.PointcloudToTensor()\n",
        "    ])\n",
        "    test_transforms = transforms.Compose([\n",
        "        d_utils.PointcloudToTensor()\n",
        "    ])\n",
        "    \n",
        "    train_dataset = ModelNet40Cls(num_points = args.num_points, root = args.data_root, transforms=train_transforms)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True, \n",
        "        num_workers=int(args.workers), \n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_dataset = ModelNet40Cls(num_points = args.num_points, root = args.data_root, transforms=test_transforms, train=False)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, \n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False, \n",
        "        num_workers=int(args.workers), \n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    model = DensePoint(num_classes = args.num_classes, input_channels = args.input_channels, use_xyz = True)\n",
        "    model.cuda()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(), lr=args.base_lr, weight_decay=args.weight_decay)\n",
        "\n",
        "    lr_lbmd = lambda e: max(args.lr_decay**(e // args.decay_step), args.lr_clip / args.base_lr)\n",
        "    bnm_lmbd = lambda e: max(args.bn_momentum * args.bn_decay**(e // args.decay_step), args.bnm_clip)\n",
        "    lr_scheduler = lr_sched.LambdaLR(optimizer, lr_lbmd)\n",
        "    bnm_scheduler = pt_utils.BNMomentumScheduler(model, bnm_lmbd)\n",
        "    \n",
        "    if args.checkpoint is not '':\n",
        "        model.load_state_dict(torch.load(args.checkpoint))\n",
        "        print('Load model successfully: %s' % (args.checkpoint))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    num_batch = len(train_dataset)/args.batch_size\n",
        "    \n",
        "    # training\n",
        "    train(train_dataloader, test_dataloader, model, criterion, optimizer, lr_scheduler, bnm_scheduler, args, num_batch)\n",
        "    \n",
        "\n",
        "def train(train_dataloader, test_dataloader, model, criterion, optimizer, lr_scheduler, bnm_scheduler, args, num_batch):\n",
        "    PointcloudScaleAndTranslate = d_utils.PointcloudScaleAndTranslate()   # initialize augmentation\n",
        "    global g_acc \n",
        "    g_acc = 0.91    # only save the model whose acc > 0.91\n",
        "    batch_count = 0\n",
        "    model.train()\n",
        "    for epoch in range(args.epochs):\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step(epoch)\n",
        "            if bnm_scheduler is not None:\n",
        "                bnm_scheduler.step(epoch-1)\n",
        "            points, target = data\n",
        "            points, target = points.cuda(), target.cuda()\n",
        "            points, target = Variable(points), Variable(target)\n",
        "            \n",
        "            # farthest point sampling\n",
        "            fps_idx = pointnet2_utils.furthest_point_sample(points, 1200)  # (B, npoint)\n",
        "            fps_idx = fps_idx[:, np.random.choice(1200, args.num_points, False)]\n",
        "            points = pointnet2_utils.gather_operation(points.transpose(1, 2).contiguous(), fps_idx).transpose(1, 2).contiguous()  # (B, N, 3)\n",
        "            \n",
        "            # augmentation\n",
        "            points.data = PointcloudScaleAndTranslate(points.data)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            pred = model(points)\n",
        "            target = target.view(-1)\n",
        "            loss = criterion(pred, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % args.print_freq_iter == 0:\n",
        "                print('[epoch %3d: %3d/%3d] \\t train loss: %0.6f \\t lr: %0.5f' %(epoch+1, i, num_batch, loss.data.clone(), lr_scheduler.get_lr()[0]))\n",
        "            batch_count += 1\n",
        "            \n",
        "            # validation in between an epoch\n",
        "            if args.evaluate and batch_count % int(args.val_freq_epoch * num_batch) == 0:\n",
        "                validate(test_dataloader, model, criterion, args, batch_count)\n",
        "\n",
        "\n",
        "def validate(test_dataloader, model, criterion, args, iter): \n",
        "    global g_acc\n",
        "    model.eval()\n",
        "    losses, preds, labels = [], [], []\n",
        "    for j, data in enumerate(test_dataloader, 0):\n",
        "        points, target = data\n",
        "        points, target = points.cuda(), target.cuda()\n",
        "        points, target = Variable(points, volatile=True), Variable(target, volatile=True)\n",
        "        \n",
        "        # farthest point sampling\n",
        "        fps_idx = pointnet2_utils.furthest_point_sample(points, args.num_points)  # (B, npoint)\n",
        "        # fps_idx = fps_idx[:, np.random.choice(1200, args.num_points, False)]\n",
        "        points = pointnet2_utils.gather_operation(points.transpose(1, 2).contiguous(), fps_idx).transpose(1, 2).contiguous()\n",
        "\n",
        "        pred = model(points)\n",
        "        target = target.view(-1)\n",
        "        loss = criterion(pred, target)\n",
        "        losses.append(loss.data.clone())\n",
        "        _, pred_choice = torch.max(pred.data, -1)\n",
        "        \n",
        "        preds.append(pred_choice)\n",
        "        labels.append(target.data)\n",
        "        \n",
        "    preds = torch.cat(preds, 0)\n",
        "    labels = torch.cat(labels, 0)\n",
        "    acc = (preds == labels).sum() / labels.numel()\n",
        "    print('\\nval loss: %0.6f \\t acc: %0.6f\\n' %(np.array(losses).mean(), acc))\n",
        "    if acc > g_acc:\n",
        "        g_acc = acc\n",
        "        torch.save(model.state_dict(), '%s/cls_iter_%d_acc_%0.6f.pth' % (args.save_path, iter, acc))\n",
        "    model.train()\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-eab3405639ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDensePointCls_L6\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDensePoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelNet40Cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0m_check_cuda_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m                                \u001b[0;34m\"PyTorch has CUDA Version={}.{} and torchvision has CUDA Version={}.{}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                \u001b[0;34m\"Please reinstall the torchvision that matches your PyTorch install.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                .format(t_major, t_minor, tv_major, tv_minor))\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=10.2 and torchvision has CUDA Version=10.1. Please reinstall the torchvision that matches your PyTorch install."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mT6XvcZid5p"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}